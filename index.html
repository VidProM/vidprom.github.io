<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<link href="https://fonts.googleapis.com/css2?family=Open+Sans&display=swap"
      rel="stylesheet">
<link rel="stylesheet" type="text/css" href="./resources/style.css" media="screen"/>

<html lang="en">
<head>
  	<title>VidProM</title>
      <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/
          if you update and want to force Facebook to re-scrape. -->
  	<meta property="og:image" content="Path to my teaser.jpg"/>
  	<meta property="og:title" content="Creative and Descriptive Paper Title." />
  	<meta property="og:description" content="Paper description." />
    <!-- Twitter automatically scrapes this. Go to https://cards-dev.twitter.com/validator?
        if you update and want to force Twitter to re-scrape. -->
    <meta property="twitter:card"          content="summary" />
    <meta property="twitter:title"         content="Creative and Descriptive Paper Title." />
    <meta property="twitter:description"   content="Paper description." />
    <meta property="twitter:image"         content="Path to my teaser.jpg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Add your Google Analytics tag here -->
    <script async
            src="https://www.googletagmanager.com/gtag/js?id=UA-97476543-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());
        gtag('config', 'UA-97476543-1');
    </script>

</head>

<body>
<div class="container">
    <div class="title">
        VidProM: A Million-scale Real Prompt-Gallery Dataset for Text-to-Video Diffusion Models
    </div>

    <div class="venue">
        Arxiv 2024
    </div>

    <br><br>

    <div class="author">
        <a href="https://wangwenhao0716.github.io/">Wenhao Wang</a><sup>1</sup>
    </div>
    <div class="author">
        <a href="https://yifansun-reid.github.io/">Yifan Sun</a><sup>2</sup>
    </div>
    <div class="author">
        <a href="https://scholar.google.com/citations?user=RMSuNFwAAAAJ&hl=en">Yi Yang</a><sup>3</sup>
    </div>
    <br><br>

    <div class="affiliation"><sup>1&nbsp;</sup>University of Technology Sydney</div>
    <div class="affiliation"><sup>2&nbsp;</sup>Baidu Inc.</div>
    <div class="affiliation"><sup>3&nbsp;</sup>Zhejiang University</div>

    <br><br>

    <div class="links"><a href="https://arxiv.org/abs/2403.06098">[Paper]</a></div>
    <div class="links"><a href="https://huggingface.co/datasets/WenhaoWang/VidProM">[Data]</a></div>
    <div class="links"><a href="https://github.com/WangWenhao0716/VidProM">[Code]</a></div>

    <br><br>

    <img style="width: 80%;" src="./resources/teaser.jpg" alt="Teaser figure."/>
    <br>
    <p style="width: 80%;">
        VidProM is the first dataset featuring 1.67 million unique text-to-video prompts and 6.69 million videos generated from 4 different state-of-the-art diffusion models. It inspires many exciting new research areas, such as Text-to-Video Prompt Engineering, Efficient Video Generation, Fake Video Detection, and Video Copy Detection for Diffusion Models.
    </p>

    <br><br>
    <hr>

    <h1>Abstract</h1>
    <p style="width: 80%;">
        The arrival of Sora marks a new era for text-to-video diffusion models, bringing significant advancements in video generation and potential applications. However, Sora, along with other text-to-video diffusion models, is highly reliant on prompts, and there is no publicly available dataset that features a study of text-to-video prompts. In this paper, we introduce VidProM, the first large-scale dataset comprising 1.67 Million unique text-to-Video Prompts from real users. Additionally, this dataset includes 6.69 million videos generated by four state-of-the-art diffusion models, alongside some related data. We initially discuss the curation of this large-scale dataset, a process that is both time-consuming and costly. Subsequently, we underscore the need for a new prompt dataset specifically designed for text-to-video generation by illustrating how VidProM differs from DiffusionDB, a large-scale prompt-gallery dataset for image generation. Our extensive and diverse dataset also opens up many exciting new research areas. For instance, we suggest exploring text-to-video prompt engineering, efficient video generation, and video copy detection for diffusion models to develop better, more efficient, and safer models.
    </p>

    <br><br>
    <hr>

    <h1>Datapoint</h1>
    <img style="width: 80%;" src="./resources/datapoint.jpg"
         alt="A data point in the proposed VidProM"/>
    <br>
    <a class="links" href="https://github.com/elliottwu/webpage-template">[Code]</a>

    <br><br>
    <hr>

    <h1>Basic information of VidProM and DiffusionDB</h1>
    <img style="width: 80%;" src="./resources/compare_table.jpg"
         alt="Results figure"/>

    <br><br>
    <hr>

    <h1>Paper</h1>
    <div class="paper-thumbnail">
        <a href="https://arxiv.org">
            <img class="layered-paper-big" width="100%" src="./resources/paper.jpg" alt="Paper thumbnail"/>
        </a>
    </div>
    <div class="paper-info">
        <h3>Creative and Descriptive Paper Title</h3>
        <p>First Author, Second Author, Third Author, Fourth Author, and Fifth Author</p>
        <p>In Conference, 20XX.</p>
        <pre><code>@InProceedings{author20XXtitle,
    title = {Creative and Descriptive Paper Title},
    author = {Author, First and Author, Second and Author, Third and Author, Fourth and Author, Fifth},
    booktitle = {Conference},
    year = {20XX},
}</code></pre>
    </div>

    <br><br>
    <hr>

    <h1>Acknowledgements</h1>
    <p style="width: 80%;">
        This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful project</a>, and inherits the modifications made by <a href="https://github.com/jasonyzhang/webpage-template">Jason Zhang</a>.
        The code can be found <a href="https://github.com/elliottwu/webpage-template">here</a>.
    </p>

    <br><br>
</div>

</body>

</html>
